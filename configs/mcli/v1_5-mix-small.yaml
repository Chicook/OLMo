run_name: olmo-small-dolma-150B-mcli  # can't have "_" or "." here
image: mosaicml/pytorch:2.0.1_cu118-python3.10-ubuntu20.04
gpu_num: 8
cluster: r12z3
gpu_type: a100_40gb
integrations:
  - integration_type: git_repo
    git_repo: allenai/LLM
    git_branch: dolma_small
    pip_install: -e .
    ssh_clone: true
command: |-
  pip freeze
  mkdir -p /root/.cache/torch/
  pip install --upgrade torch==2.0.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

  export CUDA_LAUNCH_BLOCKING=1
  export OMP_NUM_THREADS=8
  export LOG_FILTER_TYPE=local_rank0_only
  export OLMO_NO_SSL=1
  export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128

  cd LLM

  torchrun --nproc_per_node 8 scripts/train.py configs/v1_5-mix-small-mitch-ish-mcli.yaml --max_duration=36000 --scheduler.t_max=72000